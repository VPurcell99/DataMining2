{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vincent Purcell\r\n",
    "## Data Mining 2 - HW1 K Folds\r\n",
    "## Some of code is modified from the code Professor Breitzman provided us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import numpy\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty_or_blank(msg):\r\n",
    "    return re.search(\"^\\s*$\", msg)\r\n",
    "\r\n",
    "with open('water_potability.csv') as csv_file:\r\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\r\n",
    "    line_count = 0\r\n",
    "    columns = []\r\n",
    "    data = []\r\n",
    "    for row in csv_reader:\r\n",
    "        if line_count == 0:\r\n",
    "            data_series = pd.Series(row)\r\n",
    "            features = list(data_series)\r\n",
    "            columns = row\r\n",
    "            line_count += 1\r\n",
    "        else:\r\n",
    "            data_series = pd.Series(row)\r\n",
    "            data_row = list(data_series)\r\n",
    "            result = any([is_empty_or_blank(elem) for elem in data_row])\r\n",
    "            if result == False:\r\n",
    "                data.append([float(i) for i in data_row])\r\n",
    "\r\n",
    "data = numpy.array(data)\r\n",
    "X = data[:,0:9]\r\n",
    "Y = data[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity', 'Potability']\n",
      "[8.31676588e+00 2.14373394e+02 2.20184174e+04 8.05933238e+00\n",
      " 3.56886136e+02 3.63266516e+02 1.84365245e+01 1.00341674e+02\n",
      " 4.62877054e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Columns and example data row\r\n",
    "print(columns)\r\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=35, shuffle=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=35, shuffle=True)\r\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "\n",
      "[   5   15   22   27   29   33   36   40   42   43   47   67   68   69\n",
      "   73   74   76   81   87   94   99  101  110  116  119  131  133  134\n",
      "  138  143  149  158  168  176  183  202  205  214  215  218  220  221\n",
      "  223  224  227  230  233  238  239  242  253  261  262  268  269  278\n",
      "  279  281  282  288  292  295  296  298  299  300  305  316  318  319\n",
      "  323  327  334  335  336  337  344  347  348  351  357  360  364  367\n",
      "  368  369  371  376  386  387  392  397  401  408  427  430  434  440\n",
      "  442  444  449  454  460  464  473  474  479  486  489  493  510  513\n",
      "  516  517  522  539  541  548  551  553  561  567  572  574  586  589\n",
      "  591  597  600  613  614  615  620  629  644  645  652  658  678  679\n",
      "  684  688  689  693  697  703  707  717  721  723  727  737  738  740\n",
      "  742  750  755  756  757  762  764  771  779  786  788  789  790  791\n",
      "  801  804  805  810  814  827  828  834  842  854  861  867  869  874\n",
      "  885  893  897  898  899  903  907  912  916  918  919  924  934  943\n",
      "  944  945  948  954  960  968  973  985  987  992  995 1009 1016 1021\n",
      " 1023 1030 1035 1047 1050 1056 1067 1083 1091 1096 1101 1108 1113 1116\n",
      " 1125 1131 1140 1141 1144 1145 1148 1149 1153 1157 1165 1178 1192 1197\n",
      " 1198 1202 1208 1212 1213 1217 1223 1226 1240 1241 1242 1256 1261 1263\n",
      " 1279 1305 1312 1315 1317 1322 1335 1343 1360 1370 1377 1378 1382 1383\n",
      " 1384 1386 1387 1390 1391 1401 1413 1417 1418 1419 1426 1435 1444 1446\n",
      " 1448 1451 1452 1457 1464 1471 1479 1480 1482 1488 1497 1501 1503 1507\n",
      " 1509 1512 1515 1522 1524 1525 1528 1530 1537 1543 1558 1559 1560 1561\n",
      " 1562 1564 1570 1574 1579 1583 1584 1585 1590 1608 1617 1618 1619 1624\n",
      " 1628 1630 1642 1643 1644 1646 1648 1650 1653 1657 1658 1672 1678 1679\n",
      " 1681 1689 1697 1699 1703 1706 1707 1711 1712 1715 1718 1723 1725 1730\n",
      " 1741 1766 1767 1769 1773 1777 1797 1802 1804 1807 1808 1810 1815 1816\n",
      " 1819 1824 1825 1833 1838 1852 1860 1866 1868 1876 1877 1882 1889 1894\n",
      " 1896 1905 1906 1911 1912 1915 1916 1919 1926 1927 1930 1936 1942 1957\n",
      " 1963 1965 1970 1976 1979 1980 1984 1985 1987 1988 1999]\n",
      "\n",
      "\n",
      "Split 2:\n",
      "\n",
      "[   4    6   10   17   18   19   24   25   31   34   45   51   52   54\n",
      "   56   61   63   70   72   75   78   80   86   97  100  112  114  117\n",
      "  118  128  142  155  160  161  162  163  164  165  169  174  187  189\n",
      "  198  204  213  245  246  247  256  257  258  259  260  267  273  277\n",
      "  285  286  289  297  304  322  324  326  331  333  343  350  355  356\n",
      "  359  362  370  373  390  391  394  398  404  411  412  415  416  417\n",
      "  422  425  431  432  439  443  450  461  468  469  472  482  491  495\n",
      "  497  500  502  514  518  527  529  531  535  540  543  547  554  562\n",
      "  576  579  580  581  584  585  593  594  596  607  619  621  626  633\n",
      "  634  640  643  649  653  657  660  661  665  667  669  677  680  681\n",
      "  682  690  713  720  729  731  735  745  751  752  754  758  772  785\n",
      "  794  813  819  821  822  825  826  833  835  836  845  848  850  852\n",
      "  856  857  859  862  870  872  881  882  884  888  894  896  901  902\n",
      "  915  922  923  925  928  929  939  949  950  953  961  972  974  976\n",
      "  977  983  986  988  990  991  994 1014 1017 1022 1024 1027 1038 1041\n",
      " 1042 1045 1046 1054 1058 1059 1062 1066 1068 1073 1078 1080 1085 1089\n",
      " 1099 1102 1104 1124 1129 1130 1136 1137 1138 1151 1154 1158 1163 1177\n",
      " 1182 1183 1185 1189 1193 1195 1203 1206 1209 1216 1236 1239 1258 1265\n",
      " 1268 1283 1286 1292 1294 1302 1306 1309 1333 1341 1348 1355 1359 1362\n",
      " 1369 1375 1379 1385 1389 1396 1398 1400 1403 1405 1407 1425 1436 1440\n",
      " 1445 1447 1453 1460 1466 1475 1477 1484 1486 1491 1493 1499 1506 1511\n",
      " 1513 1535 1536 1546 1548 1556 1566 1567 1572 1586 1588 1591 1593 1597\n",
      " 1599 1600 1603 1609 1610 1611 1615 1616 1621 1625 1629 1636 1639 1641\n",
      " 1655 1656 1660 1662 1671 1677 1682 1684 1686 1687 1693 1702 1705 1710\n",
      " 1713 1717 1720 1727 1728 1729 1736 1746 1748 1749 1750 1756 1761 1762\n",
      " 1765 1771 1778 1779 1782 1794 1796 1799 1800 1805 1814 1837 1841 1842\n",
      " 1850 1853 1859 1863 1864 1869 1871 1872 1878 1883 1884 1890 1898 1901\n",
      " 1909 1913 1924 1929 1931 1940 1946 1949 1954 1955 1967 1968 1971 1975\n",
      " 1986 1991 1994 1998 2000 2002 2005 2007 2008 2009]\n",
      "\n",
      "\n",
      "Split 3:\n",
      "\n",
      "[   2    8    9   21   23   26   35   39   46   49   55   59   60   77\n",
      "   82   92   96  102  105  106  107  113  121  122  124  126  129  130\n",
      "  139  145  146  150  152  153  154  156  157  175  180  185  191  194\n",
      "  196  203  208  216  217  226  228  231  232  234  236  237  240  241\n",
      "  250  280  284  293  312  313  314  315  317  320  325  329  341  346\n",
      "  353  365  372  379  380  382  383  384  389  395  399  400  403  405\n",
      "  406  407  409  410  413  421  423  435  436  446  448  455  456  458\n",
      "  466  470  471  476  477  478  480  488  496  501  504  515  521  525\n",
      "  534  542  552  555  556  559  560  570  578  583  590  592  599  601\n",
      "  605  609  610  611  617  618  622  628  630  632  635  636  641  642\n",
      "  648  651  662  670  673  676  686  706  708  709  711  712  716  725\n",
      "  728  736  741  748  775  776  780  781  783  787  793  795  796  797\n",
      "  799  806  811  817  818  829  831  832  837  841  844  849  853  855\n",
      "  860  863  865  866  883  889  890  891  905  906  910  911  913  914\n",
      "  917  920  921  937  940  942  947  952  955  965  967  979  980  989\n",
      "  993  998  999 1006 1011 1018 1019 1020 1036 1043 1048 1049 1052 1060\n",
      " 1063 1064 1074 1076 1077 1086 1087 1094 1095 1098 1107 1120 1127 1134\n",
      " 1135 1143 1152 1156 1162 1166 1167 1170 1174 1176 1186 1187 1188 1191\n",
      " 1199 1204 1214 1220 1222 1229 1230 1235 1238 1248 1249 1253 1254 1267\n",
      " 1272 1276 1278 1280 1282 1290 1296 1297 1308 1321 1325 1328 1331 1337\n",
      " 1338 1339 1340 1346 1350 1351 1354 1356 1357 1361 1363 1366 1374 1380\n",
      " 1397 1409 1411 1415 1416 1428 1429 1433 1438 1443 1449 1450 1458 1462\n",
      " 1473 1481 1483 1485 1494 1495 1498 1505 1517 1519 1520 1523 1526 1529\n",
      " 1531 1532 1539 1552 1568 1582 1589 1592 1601 1604 1605 1606 1607 1620\n",
      " 1632 1633 1635 1645 1652 1654 1666 1667 1683 1685 1694 1695 1700 1719\n",
      " 1721 1733 1734 1735 1745 1753 1754 1758 1759 1763 1776 1781 1783 1786\n",
      " 1793 1795 1813 1820 1821 1822 1827 1830 1831 1840 1843 1854 1858 1861\n",
      " 1862 1874 1875 1879 1897 1907 1910 1917 1928 1938 1939 1941 1948 1951\n",
      " 1956 1959 1962 1966 1974 1977 1978 1992 1996 2003]\n",
      "\n",
      "\n",
      "Split 4:\n",
      "\n",
      "[   0    1    7   11   12   13   14   20   28   37   38   41   57   62\n",
      "   64   65   66   71   84   85   88   93   98  103  104  109  115  120\n",
      "  123  127  132  135  136  137  140  144  151  159  166  170  173  178\n",
      "  186  190  193  195  197  209  210  211  212  229  235  244  249  263\n",
      "  265  266  271  272  274  276  291  301  302  307  308  309  328  330\n",
      "  332  339  342  345  352  361  363  366  374  377  393  396  402  414\n",
      "  418  419  424  428  429  433  438  447  451  459  462  465  487  494\n",
      "  498  499  503  506  507  509  520  523  526  528  536  537  550  558\n",
      "  563  568  573  582  598  602  603  604  606  612  616  623  625  638\n",
      "  639  647  654  655  663  664  666  672  674  675  683  687  692  695\n",
      "  698  699  700  704  714  715  722  724  732  733  734  739  743  746\n",
      "  753  759  761  766  768  769  770  777  778  784  798  800  803  815\n",
      "  820  823  838  839  840  843  846  847  851  864  871  875  876  895\n",
      "  908  909  926  931  935  936  946  956  958  963  964  969  970  971\n",
      "  975  978  996 1001 1002 1005 1007 1013 1015 1028 1032 1034 1037 1039\n",
      " 1040 1055 1070 1071 1075 1082 1088 1090 1093 1106 1110 1111 1112 1114\n",
      " 1119 1121 1122 1123 1126 1132 1142 1147 1159 1160 1161 1169 1172 1179\n",
      " 1181 1201 1205 1211 1218 1224 1225 1227 1231 1237 1243 1244 1247 1257\n",
      " 1259 1269 1270 1271 1274 1284 1285 1293 1298 1300 1307 1310 1311 1313\n",
      " 1316 1318 1320 1323 1326 1327 1329 1330 1336 1352 1353 1358 1364 1367\n",
      " 1368 1371 1372 1376 1381 1388 1392 1395 1399 1402 1404 1406 1410 1412\n",
      " 1420 1430 1432 1437 1439 1441 1442 1456 1461 1463 1468 1469 1470 1489\n",
      " 1492 1500 1508 1514 1516 1527 1533 1534 1538 1542 1547 1550 1553 1554\n",
      " 1557 1563 1565 1573 1576 1596 1598 1602 1613 1622 1623 1631 1634 1637\n",
      " 1640 1649 1664 1669 1670 1691 1692 1701 1704 1724 1726 1731 1744 1747\n",
      " 1751 1755 1760 1764 1768 1770 1774 1780 1785 1790 1792 1801 1803 1806\n",
      " 1809 1817 1823 1826 1828 1829 1832 1835 1839 1845 1846 1849 1855 1867\n",
      " 1870 1873 1880 1887 1888 1892 1893 1899 1900 1902 1920 1921 1937 1943\n",
      " 1947 1950 1952 1958 1964 1981 1982 1983 1990 2004]\n",
      "\n",
      "\n",
      "Split 5:\n",
      "\n",
      "[   3   16   30   32   44   48   50   53   58   79   83   89   90   91\n",
      "   95  108  111  125  141  147  148  167  171  172  177  179  181  182\n",
      "  184  188  192  199  200  201  206  207  219  222  225  243  248  251\n",
      "  252  254  255  264  270  275  283  287  290  294  303  306  310  311\n",
      "  321  338  340  349  354  358  375  378  381  385  388  420  426  437\n",
      "  441  445  452  453  457  463  467  475  481  483  484  485  490  492\n",
      "  505  508  511  512  519  524  530  532  533  538  544  545  546  549\n",
      "  557  564  565  566  569  571  575  577  587  588  595  608  624  627\n",
      "  631  637  646  650  656  659  668  671  685  691  694  696  701  702\n",
      "  705  710  718  719  726  730  744  747  749  760  763  765  767  773\n",
      "  774  782  792  802  807  808  809  812  816  824  830  858  868  873\n",
      "  877  878  879  880  886  887  892  900  904  927  930  932  933  938\n",
      "  941  951  957  959  962  966  981  982  984  997 1000 1003 1004 1008\n",
      " 1010 1012 1025 1026 1029 1031 1033 1044 1051 1053 1057 1061 1065 1069\n",
      " 1072 1079 1081 1084 1092 1097 1100 1103 1105 1109 1115 1117 1118 1128\n",
      " 1133 1139 1146 1150 1155 1164 1168 1171 1173 1175 1180 1184 1190 1194\n",
      " 1196 1200 1207 1210 1215 1219 1221 1228 1232 1233 1234 1245 1246 1250\n",
      " 1251 1252 1255 1260 1262 1264 1266 1273 1275 1277 1281 1287 1288 1289\n",
      " 1291 1295 1299 1301 1303 1304 1314 1319 1324 1332 1334 1342 1344 1345\n",
      " 1347 1349 1365 1373 1393 1394 1408 1414 1421 1422 1423 1424 1427 1431\n",
      " 1434 1454 1455 1459 1465 1467 1472 1474 1476 1478 1487 1490 1496 1502\n",
      " 1504 1510 1518 1521 1540 1541 1544 1545 1549 1551 1555 1569 1571 1575\n",
      " 1577 1578 1580 1581 1587 1594 1595 1612 1614 1626 1627 1638 1647 1651\n",
      " 1659 1661 1663 1665 1668 1673 1674 1675 1676 1680 1688 1690 1696 1698\n",
      " 1708 1709 1714 1716 1722 1732 1737 1738 1739 1740 1742 1743 1752 1757\n",
      " 1772 1775 1784 1787 1788 1789 1791 1798 1811 1812 1818 1834 1836 1844\n",
      " 1847 1848 1851 1856 1857 1865 1881 1885 1886 1891 1895 1903 1904 1908\n",
      " 1914 1918 1922 1923 1925 1932 1933 1934 1935 1944 1945 1953 1960 1961\n",
      " 1969 1972 1973 1989 1993 1995 1997 2001 2006 2010]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, (train, test) in enumerate(kf.split(X), 1):\r\n",
    "    \r\n",
    "    print(f'Split {index}:\\n')\r\n",
    "    \r\n",
    "    print(test)\r\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "\n",
      "[[187  57]\n",
      " [100  59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.77      0.70       244\n",
      "         1.0       0.51      0.37      0.43       159\n",
      "\n",
      "    accuracy                           0.61       403\n",
      "   macro avg       0.58      0.57      0.57       403\n",
      "weighted avg       0.60      0.61      0.60       403\n",
      "\n",
      "\n",
      "\n",
      "Split 2:\n",
      "\n",
      "[[153  91]\n",
      " [ 61  97]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.63      0.67       244\n",
      "         1.0       0.52      0.61      0.56       158\n",
      "\n",
      "    accuracy                           0.62       402\n",
      "   macro avg       0.62      0.62      0.61       402\n",
      "weighted avg       0.64      0.62      0.63       402\n",
      "\n",
      "\n",
      "\n",
      "Split 3:\n",
      "\n",
      "[[166  71]\n",
      " [ 90  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.70      0.67       237\n",
      "         1.0       0.51      0.45      0.48       165\n",
      "\n",
      "    accuracy                           0.60       402\n",
      "   macro avg       0.58      0.58      0.58       402\n",
      "weighted avg       0.59      0.60      0.59       402\n",
      "\n",
      "\n",
      "\n",
      "Split 4:\n",
      "\n",
      "[[195  59]\n",
      " [ 80  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.77      0.74       254\n",
      "         1.0       0.54      0.46      0.49       148\n",
      "\n",
      "    accuracy                           0.65       402\n",
      "   macro avg       0.62      0.61      0.62       402\n",
      "weighted avg       0.65      0.65      0.65       402\n",
      "\n",
      "\n",
      "\n",
      "Split 5:\n",
      "\n",
      "[[127  94]\n",
      " [ 71 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.57      0.61       221\n",
      "         1.0       0.54      0.61      0.57       181\n",
      "\n",
      "    accuracy                           0.59       402\n",
      "   macro avg       0.59      0.59      0.59       402\n",
      "weighted avg       0.60      0.59      0.59       402\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "for index, (train, test) in enumerate(kf.split(X), 1):\r\n",
    "    \r\n",
    "    print(f'Split {index}:\\n')\r\n",
    "    \r\n",
    "    X_train = X[train]\r\n",
    "    X_test = X[test]\r\n",
    "    y_train = Y[train]\r\n",
    "    y_test = Y[test]\r\n",
    "    \r\n",
    "    scaler.fit(X_train)\r\n",
    "    \r\n",
    "    X_train = scaler.transform(X_train)\r\n",
    "    X_test = scaler.transform(X_test)\r\n",
    "    \r\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(30,30,30,3), max_iter=2000)\r\n",
    "    mlp.fit(X_train,y_train)\r\n",
    "    predictions = mlp.predict(X_test)\r\n",
    "\r\n",
    "    print(confusion_matrix(y_test, predictions))\r\n",
    "    print(classification_report(y_test, predictions))\r\n",
    "    \r\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8701f80c374d04af0e91f6be4c5e64730e695461425753d44c3710c84263da43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}